{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>AANG - Is This The End ?</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import xarray\n",
    "\n",
    "# Loading High Resolution ERA5 Dataset\n",
    "data = xarray.open_zarr('gs://weatherbench2/datasets/era5/1959-2023_01_10-full_37-1h-0p25deg-chunk-1.zarr/')\n",
    "print(\"Done accessing google\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.load** : load everything into memory\n",
    "\n",
    "**.compute** : compute all the lazy operations and then load into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the time taken to load one sample of the data\n",
    "#\n",
    "#\n",
    "execution_times, file_sizes = list(), list()\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    # Loading a subset of the data\n",
    "    d = data.isel(time = i)\n",
    "\n",
    "    # Proving that the data is not loaded\n",
    "    print(\"Data Value (before) = \", d[\"temperature\"].data[0,0,0])\n",
    "\n",
    "    # Timing\n",
    "    start_time = time.time()\n",
    "    d = d.compute()\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Proving that the data is loaded\n",
    "    print(\"Data Value (after) = \", d[\"temperature\"].data[0,0,0])\n",
    "\n",
    "    # Compute the execution time and file size [MB]\n",
    "    execution_time = end_time - start_time\n",
    "    execution_times.append(execution_time)\n",
    "    file_size = d.nbytes / 1e6\n",
    "    file_sizes.append(file_size)\n",
    "    d.close()\n",
    "\n",
    "for i, exec_time in enumerate(execution_times, start=1):\n",
    "    print(f\"Exécution {i}: {exec_time:.4f} secondes pour un fichier de {file_size:.2f} MB\")\n",
    "print(\"Exécution (moyenne) : \", sum(execution_times) / len(execution_times), \"secondes pour un fichier de taille moyenne\", sum(file_sizes) / len(file_sizes), \"MB\")\n",
    "print(\"Vitesse de téléchargement : \", sum(file_sizes) / sum(execution_times), \"MB/s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the time taken to load one sample of the data\n",
    "#\n",
    "#\n",
    "execution_times, file_sizes = list(), list()\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    # Loading a subset of the data\n",
    "    d = data.isel(time = slice(0, 12))\n",
    "\n",
    "    # Nombre de samples\n",
    "    nb_samples = d.time.size\n",
    "\n",
    "    # Proving that the data is not loaded\n",
    "    print(\"Data Value (before) = \", d[\"temperature\"].data[0,0,0])\n",
    "\n",
    "    # Timing\n",
    "    start_time = time.time()\n",
    "    d = d.compute()\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Proving that the data is loaded\n",
    "    print(\"Data Value (after) = \", d[\"temperature\"].data[0,0,0])\n",
    "\n",
    "    # Compute the execution time and file size [MB]\n",
    "    execution_time = end_time - start_time\n",
    "    print(\"Execution time (current) = \", execution_time)\n",
    "    execution_times.append(execution_time)\n",
    "    file_size = d.nbytes / 1e6\n",
    "    file_sizes.append(file_size)\n",
    "    d.close()\n",
    "\n",
    "for i, exec_time in enumerate(execution_times, start=1):\n",
    "    print(f\"Exécution {i}: {exec_time:.4f} secondes pour un fichier de {file_size:.2f} MB\")\n",
    "print(\"Exécution (moyenne) : \", sum(execution_times) / len(execution_times), \"secondes pour un fichier de taille moyenne\", sum(file_sizes) / len(file_sizes), \"MB\")\n",
    "print(\"Vitesse de téléchargement (toute la séquence) : \", sum(file_sizes) / sum(execution_times), \"MB/s\")\n",
    "print(\"Vitesse de téléchargement (par élément) : \", (sum(file_sizes) / sum(execution_times) / nb_samples), \"MB/s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Value (before) =  dask.array<getitem, shape=(1440,), dtype=float32, chunksize=(1440,), chunktype=numpy.ndarray>\n",
    "Data Value (after) =  [257.4223 257.4223 257.4223 ... 257.4223 257.4223 257.4223]\n",
    "Execution time (current) =  136.18462133407593\n",
    "Data Value (before) =  dask.array<getitem, shape=(1440,), dtype=float32, chunksize=(1440,), chunktype=numpy.ndarray>\n",
    "Data Value (after) =  [257.4223 257.4223 257.4223 ... 257.4223 257.4223 257.4223]\n",
    "Execution time (current) =  133.50841426849365\n",
    "Data Value (before) =  dask.array<getitem, shape=(1440,), dtype=float32, chunksize=(1440,), chunktype=numpy.ndarray>\n",
    "Data Value (after) =  [257.4223 257.4223 257.4223 ... 257.4223 257.4223 257.4223]\n",
    "Execution time (current) =  134.8579182624817\n",
    "Data Value (before) =  dask.array<getitem, shape=(1440,), dtype=float32, chunksize=(1440,), chunktype=numpy.ndarray>\n",
    "Data Value (after) =  [257.4223 257.4223 257.4223 ... 257.4223 257.4223 257.4223]\n",
    "Execution time (current) =  125.42817306518555\n",
    "Data Value (before) =  dask.array<getitem, shape=(1440,), dtype=float32, chunksize=(1440,), chunktype=numpy.ndarray>\n",
    "Data Value (after) =  [257.4223 257.4223 257.4223 ... 257.4223 257.4223 257.4223]\n",
    "Execution time (current) =  117.14391827583313\n",
    "Exécution 1: 136.1846 secondes pour un fichier de 14356.79 MB\n",
    "Exécution 2: 133.5084 secondes pour un fichier de 14356.79 MB\n",
    "Exécution 3: 134.8579 secondes pour un fichier de 14356.79 MB\n",
    "Exécution 4: 125.4282 secondes pour un fichier de 14356.79 MB\n",
    "Exécution 5: 117.1439 secondes pour un fichier de 14356.79 MB\n",
    "Exécution (moyenne) :  129.42460904121398 secondes pour un fichier de taille moyenne 14356.791756 MB\n",
    "Vitesse de téléchargement (toute la séquence) :  110.92783561299552 MB/s\n",
    "Vitesse de téléchargement (par élément) :  9.24398630108296 MB/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    <center>AANG - Checking Memory</center>\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full High-Resolution Dataset\n",
    "data_hr = xarray.open_zarr('gs://weatherbench2/datasets/era5/1959-2023_01_10-full_37-1h-0p25deg-chunk-1.zarr/')\n",
    "\n",
    "# Mid-Resolution Dataset\n",
    "data_mr = xarray.open_zarr('gs://weatherbench2/datasets/era5/1959-2023_01_10-full_37-1h-512x256_equiangular_conservative.zarr')\n",
    "\n",
    "# Low-Resolution Dataset\n",
    "data_lr = xarray.open_zarr('gs://weatherbench2/datasets/era5/1959-2022-1h-360x181_equiangular_with_poles_conservative.zarr/')\n",
    "\n",
    "# Very Low-Resolution Dataset\n",
    "data_vlr = xarray.open_zarr('gs://weatherbench2/datasets/era5/1959-2022-1h-240x121_equiangular_with_poles_conservative.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ease of access and crying\n",
    "ds_data  = [data_hr, data_mr, data_lr, data_vlr]\n",
    "ds_names = [\"High Resolution (1440 x 721)\", \"Mid Resolution (512 x 256)\", \"Low Resolution (360 x 181)\", \"Very Low Resolution (240 x 121)\"]\n",
    "\n",
    "# Checking total size of the datasets (FULL)\n",
    "print(\"----- COMPLETE DATASET : 1959 -> 2023 -----\")\n",
    "for d, n in zip(ds_data, ds_names):\n",
    "    print(f\"{n} = {d.nbytes // 1e12} TB\")\n",
    "\n",
    "# Filtering time\n",
    "print(\"----- TIME FILTERED DATASET (1) : 2000 -> 2023 -----\")\n",
    "\n",
    "start_time = '2000-01-01T00:00:00.000000000'\n",
    "end_time   = '2023-01-01T00:00:00.000000000'\n",
    "\n",
    "for d, n in zip(ds_data, ds_names):\n",
    "    print(f\"{n} = {d.sel(time = slice(start_time, end_time)).nbytes // 1e12} TB\")\n",
    "\n",
    "print(\"----- TIME FILTERED DATASET (2) : 2010 -> 2023 -----\")\n",
    "\n",
    "start_time = '2010-01-01T00:00:00.000000000'\n",
    "end_time   = '2023-01-01T00:00:00.000000000'\n",
    "\n",
    "for d, n in zip(ds_data, ds_names):\n",
    "    print(f\"{n} = {d.sel(time = slice(start_time, end_time)).nbytes // 1e12} TB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- COMPLETE DATASETS : 1959 -> 2023 -----\n",
    "High Resolution (1440 x 721) = 668.0 TB\n",
    "Mid Resolution (512 x 256) = 84.0 TB\n",
    "Low Resolution (360 x 181) = 33.0 TB\n",
    "Very Low Resolution (240 x 121) = 14.0 TB\n",
    "----- TIME FILTERED DATASETS (1) : 2000 -> 2023 -----\n",
    "High Resolution (1440 x 721) = 240.0 TB\n",
    "Mid Resolution (512 x 256) = 30.0 TB\n",
    "Low Resolution (360 x 181) = 11.0 TB\n",
    "Very Low Resolution (240 x 121) = 5.0 TB\n",
    "----- TIME FILTERED DATASETS (2) : 2010 -> 2023 -----\n",
    "High Resolution (1440 x 721) = 135.0 TB\n",
    "Mid Resolution (512 x 256) = 17.0 TB\n",
    "Low Resolution (360 x 181) = 6.0 TB\n",
    "Very Low Resolution (240 x 121) = 2.0 TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphcast Variables\n",
    "graphcast_surface_variables     = [\"2m_temperature\", \"10m_u_component_of_wind\", \"10m_v_component_of_wind\", \"mean_sea_level_pressure\", \"total_precipitation\"]\n",
    "graphcast_atmospheric_variables = [\"temperature\", \"u_component_of_wind\", \"v_component_of_wind\", \"geopotential\", \"specific_humidity\", \"vertical_velocity\"]\n",
    "graphcast_variables = graphcast_surface_variables + graphcast_atmospheric_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- GRAPHCAST DATASET : 1959 -> 2023 -----\n",
      "High Resolution (1440 x 721) = 529.0 TB\n",
      "Mid Resolution (512 x 256) = 66.0 TB\n",
      "Low Resolution (360 x 181) = 32.0 TB\n",
      "Very Low Resolution (240 x 121) = 14.0 TB\n",
      "----- GRAPHCAST TIME FILTERED DATASET (1) : 2000 -> 2023 -----\n",
      "High Resolution (1440 x 721) = 190.0 TB\n",
      "Mid Resolution (512 x 256) = 23.0 TB\n",
      "Low Resolution (360 x 181) = 11.0 TB\n",
      "Very Low Resolution (240 x 121) = 5.0 TB\n",
      "----- GRAPHCAST TIME FILTERED DATASET (2) : 2010 -> 2023 -----\n",
      "High Resolution (1440 x 721) = 107.0 TB\n",
      "Mid Resolution (512 x 256) = 13.0 TB\n",
      "Low Resolution (360 x 181) = 6.0 TB\n",
      "Very Low Resolution (240 x 121) = 2.0 TB\n"
     ]
    }
   ],
   "source": [
    "# Checking total size of the datasets (FULL)\n",
    "print(\"----- GRAPHCAST DATASET : 1959 -> 2023 -----\")\n",
    "for d, n in zip(ds_data, ds_names):\n",
    "    ds = d.drop_vars([var for var in d.data_vars if var not in graphcast_variables])\n",
    "    print(f\"{n} = {ds.nbytes // 1e12} TB\")\n",
    "\n",
    "# Filtering time\n",
    "print(\"----- GRAPHCAST TIME FILTERED DATASET (1) : 2000 -> 2023 -----\")\n",
    "\n",
    "start_time = '2000-01-01T00:00:00.000000000'\n",
    "end_time   = '2023-01-01T00:00:00.000000000'\n",
    "\n",
    "for d, n in zip(ds_data, ds_names):\n",
    "    ds = d.sel(time = slice(start_time, end_time))\n",
    "    ds = ds.drop_vars([var for var in d.data_vars if var not in graphcast_variables])\n",
    "    print(f\"{n} = {ds.nbytes // 1e12} TB\")\n",
    "\n",
    "# Filtering time\n",
    "print(\"----- GRAPHCAST TIME FILTERED DATASET (2) : 2010 -> 2023 -----\")\n",
    "\n",
    "start_time = '2010-01-01T00:00:00.000000000'\n",
    "end_time   = '2023-01-01T00:00:00.000000000'\n",
    "\n",
    "for d, n in zip(ds_data, ds_names):\n",
    "    ds = d.sel(time = slice(start_time, end_time))\n",
    "    ds = ds.drop_vars([var for var in d.data_vars if var not in graphcast_variables])\n",
    "    print(f\"{n} = {ds.nbytes // 1e12} TB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
